#Accuracy = True Perdictions / All Predictions

Confusion Matrix
True positivies / True negatives
False positives / False negatives

True Border \ Calculated Border

Don't use Accuracy as measurement

#Recall
Precision: % of selected items that are correct
Recall: % of correct items that are selected

Recall is better measurement

#F Score
F = 2PR(P + R)

# Model Eval in Spark
Underfitting - too simple model. Line. y = ax + b
Just right!
Overfitting - too comple model. High level polynom: y = a*x^5+ ... + g


# Cross-validation
k-fold cross-validation.
It's used to test model, not for training one.
What's the purpose of Cross-validation: to pick they right model type (not to train model)

# Learning Curve
High Bias - all in one point - underfitting
High Variance - not trained well or not enough data